{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1pdEFANwWSX",
    "outputId": "4b860909-82f8-46de-ab3e-5fb4e09f672c"
   },
   "outputs": [],
   "source": [
    "! pip install biopython # Install biopython package to interact with PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "530wle5LwWSZ",
    "outputId": "66ceb3c4-edf2-4573-bd46-b57c32a1a305"
   },
   "outputs": [],
   "source": [
    "# Import the Entrez module from biopython\n",
    "from Bio import Entrez\n",
    "import time\n",
    "\n",
    "# Set the email for interact\n",
    "Entrez.email = \"annabian1122@gmail.com\"\n",
    "\n",
    "# Search for articles using a keyword\n",
    "search_term = \"Alzheimer's disease AND English[lang]\"\n",
    "handle = Entrez.esearch(db=\"pubmed\", term=search_term, retmax=20000) # Search PubMed with a limit of 20,000 results\n",
    "record = Entrez.read(handle) # Read the search results\n",
    "handle.close() # Close the handle after reading\n",
    "\n",
    "# Get the list of PubMed IDs (PMIDs) from the search results\n",
    "id_list = record[\"IdList\"]\n",
    "print(f\"Number of articles found: {len(id_list)}\")\n",
    "\n",
    "# Fetch abstracts of the articles using the PubMed IDs\n",
    "handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(id_list), rettype=\"abstract\", retmode=\"xml\")\n",
    "records = Entrez.read(handle) # Read the fetched data\n",
    "handle.close() # Close the handle after reading\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "# Initialize lists to store abstracts and corresponding PMIDs\n",
    "abstracts = []\n",
    "pmids = []\n",
    "\n",
    "import pandas as pd # Import pandas for data manipulation\n",
    "\n",
    "for start in range(0, len(id_list), batch_size):\n",
    "    end = min(start + batch_size, len(id_list))\n",
    "    batch_ids = id_list[start:end]\n",
    "\n",
    "    print(f\"Fetching records {start+1} to {end}...\")\n",
    "\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(batch_ids), rettype=\"abstract\", retmode=\"xml\") # Fetch abstracts in XML format\n",
    "    batch_records = Entrez.read(handle) # Read the fetched data\n",
    "    handle.close() # Close the handle after reading\n",
    "\n",
    "    # Loop through the fetched articles and extract abstract text and PMIDs\n",
    "    for article in batch_records['PubmedArticle']:\n",
    "        try:\n",
    "            # Extract the abstract text and join it into a single string\n",
    "            abstract_text = article['MedlineCitation']['Article']['Abstract']['AbstractText']\n",
    "            abstract_str = \" \".join(abstract_text)\n",
    "            # Extract the PubMed ID (PMID)\n",
    "            pmid = article['MedlineCitation']['PMID']\n",
    "            # Append abstract and PMID to the lists\n",
    "            abstracts.append(abstract_str)\n",
    "            pmids.append(pmid)\n",
    "        except:\n",
    "            # Skip articles without an abstract\n",
    "            continue\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "\n",
    "# Save the extracted data into a DataFrame (ensure only articles with abstracts are included)\n",
    "df = pd.DataFrame({\n",
    "    \"PMID\": pmids,\n",
    "    \"Abstract\": abstracts\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = \"alzheimers_abstracts.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(df)} abstracts to the CSV file: {csv_path}\") # Print the number of abstracts saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ubT2wZcGwWSb",
    "outputId": "46091bdf-8b9b-467d-88ef-1df37252cb44"
   },
   "outputs": [],
   "source": [
    "print(f\"len(id_list): {len(id_list)}\")\n",
    "print(f\"len(abstracts): {len(abstracts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUdQc7WbwWSb",
    "outputId": "9bbbe713-a360-4a32-bd9a-f864627582f2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the cleaned and saved abstracts data\n",
    "df = pd.read_csv(\"/content/alzheimers_abstracts.csv\")\n",
    "\n",
    "# Define a custom list of symptom-related keywords\n",
    "symptom_keywords = [\n",
    "    \"memory loss\", \"forgetfulness\", \"cognitive decline\", \"confusion\",\n",
    "    \"disorientation\", \"language impairment\", \"attention deficit\", \"behavioral change\",\n",
    "    \"mild cognitive impairment\", \"cognitive symptoms\"\n",
    "]\n",
    "\n",
    "# Add a new column 'MentionsSymptom': mark 1 if any keyword is found in the abstract, else 0\n",
    "df[\"MentionsSymptom\"] = df[\"Abstract\"].apply(\n",
    "    lambda text: int(any(kw.lower() in text.lower() for kw in symptom_keywords))\n",
    ")\n",
    "\n",
    "# Save the updated DataFrame as a new CSV file\n",
    "df.to_csv(\"alzheimers_abstracts__symptoms.csv\", index=False)\n",
    "print(\"Successfully completed keyword tagging and saved the new file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nGV9Dy2wWSb",
    "outputId": "35163f2b-3b18-4571-d547-4255c3744879"
   },
   "outputs": [],
   "source": [
    "! pip install spacy\n",
    "\n",
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WOxPCOywWSc",
    "outputId": "cc6a0d93-886d-4d13-e2e1-cf7c40e6a1f5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Load the English spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add an EntityRuler to insert custom entity recognition rules before the built-in NER\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "# Define a list of symptom keywords\n",
    "symptom_keywords = [\n",
    "    \"memory loss\", \"forgetfulness\", \"cognitive decline\", \"confusion\",\n",
    "    \"disorientation\", \"language impairment\", \"attention deficit\"\n",
    "]\n",
    "\n",
    "# Build patterns for the EntityRuler\n",
    "patterns = [{\"label\": \"SYMPTOM\", \"pattern\": kw} for kw in symptom_keywords]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "# Test entity recognition on a single sample sentence\n",
    "doc = nlp(\"The patient experienced memory loss and confusion over time.\")\n",
    "print(\"\\nTesting entity recognition on a sample sentence:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\" - {ent.text} ({ent.label_})\")\n",
    "\n",
    "# Read the abstracts dataset\n",
    "df = pd.read_csv(\"/content/alzheimers_abstracts__symptoms.csv\")\n",
    "\n",
    "# Perform entity recognition on the first 5 abstracts\n",
    "print(\"\\nBatch processing entity recognition results for abstracts: \")\n",
    "for i in range(5):\n",
    "    text = df.loc[i, \"Abstract\"]\n",
    "    print(f\"\\nAbstract #{i+1}:\\n{text}\")\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    print(\"Recognized Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\" - {ent.text} ({ent.label_})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3P7F4KZwWSc",
    "outputId": "425e6d89-85e9-4bac-eee8-c2a75c439d28"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read preprocessed dataset (with symptom labels)ï¼‰\n",
    "df = pd.read_csv(\"/content/alzheimers_abstracts__symptoms.csv\")\n",
    "\n",
    "# Split the data into training set and temporary set (dev + test)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df[\"MentionsSymptom\"])\n",
    "# 30% of data goes to dev + test, 70% to train\n",
    "\n",
    "# Further split the temporary set into dev (validation) and test sets (50% each)\n",
    "dev_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"MentionsSymptom\"])\n",
    "\n",
    "# Save the splits into separate CSV files\n",
    "train_df.to_csv(\"symptom_train.csv\", index=False)\n",
    "dev_df.to_csv(\"symptom_dev.csv\", index=False)\n",
    "test_df.to_csv(\"symptom_test.csv\", index=False)\n",
    "\n",
    "print(\"Symptom recognition train/validation/test sets have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYdcDkTgwWSc",
    "outputId": "e9d49789-8a93-42e4-cbea-216c2600fffb"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Read the previously saved training and testing datasets\n",
    "train_df = pd.read_csv(\"/content/symptom_train.csv\")\n",
    "test_df = pd.read_csv(\"/content/symptom_test.csv\")\n",
    "\n",
    "# Split features and labels\n",
    "X_train = train_df[\"Abstract\"] # Extract the abstract text for training\n",
    "y_train = train_df[\"MentionsSymptom\"] # Extract the label (whether symptom is mentioned: 0 or 1) for training\n",
    "X_test = test_df[\"Abstract\"] # Extract the abstract text for testing\n",
    "y_test = test_df[\"MentionsSymptom\"] # Extract the label for testing\n",
    "\n",
    "# Apply TF-IDF vectorization to the text\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # Keep only the top 5000 most frequent words\n",
    "X_train_vec = vectorizer.fit_transform(X_train) # Fit on training data and transform it\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=200) # Initialize the model (allow up to 200 iterations to converge)\n",
    "clf.fit(X_train_vec, y_train) # Train the model on the vectorized training data\n",
    "\n",
    "# Predict and output results\n",
    "y_pred = clf.predict(X_test_vec) # Predict the labels for test data\n",
    "print(classification_report(y_test, y_pred)) # Print precision, recall, f1-score, and support for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28N9SXqSwWSd",
    "outputId": "4c9fda70-54ec-4bab-8f43-3678df7e262c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = clf.predict(X_test_vec) # Model's predicted class (0 or 1) for each test s\n",
    "y_prob = clf.predict_proba(X_test_vec)[:, 1] # Model's predicted probability of class 1 for each sample\n",
    "\n",
    "# Print the classification report (precision, recall, F1-score, support)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate and print the ROC-AUC score\n",
    "auc = roc_auc_score(y_test, y_prob) # Area under the Receiver Operating Characteristic curve\n",
    "print(f\"ROC-AUC: {auc:.4f}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ox1F80y4EfM",
    "outputId": "71abffe4-d217-41ff-a9e8-3dd72140b650"
   },
   "outputs": [],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839,
     "referenced_widgets": [
      "a8f62461720849a9af5e862f0206ec82",
      "7502e3862df341bc9b75a59203dabdd0",
      "5908046d19e0464cad171d9730acf188",
      "dbf3435883484983a36a3acdda4ad2e7",
      "116ea5cdf3e6446a9b6a0ae5d7e86edb",
      "abc8cf0752f74883b0465cdb77c74f73",
      "a29187a7fb984b66a38285f0c4bf4a62",
      "c7244a80b11f43d48652f58715064edd",
      "ec419281e01d409e83ccedb658d0abcc",
      "64903298cea447c0bbbf3ff7822af7d3",
      "dcc7d8c9fedb417895976cde50cbddc1",
      "5ce011036f8b4d35b89bc41b62895dfc",
      "02c9e5d015844b7281a6c54fe67ca302",
      "985cb55fc98d40918d7a1506acefc775",
      "d6516a19d3124379afc89b91b0df7d84",
      "90e431f3ee024c3ea6f4f6b3f94ecf43",
      "d8b8a38507624bdf9e868e5e20646702",
      "4209fdcff6c1414393d7995d8e8a54ba",
      "14248359254846209be66a7a645a5c12",
      "32ffe21001cb4c03b3f689be2d4c9206",
      "2699d9e6127b4552ba33d146a2c86645",
      "1ef0e889d73141079fa5c98900eba5f2",
      "07e2ec324aca4028a58ee182407b0d97",
      "caba5ce3f5f24f7cb22de6761d4ec999",
      "c8bd49abec5d473fa9e7b9914e94bd04",
      "e8e68f61c584406aa2711b301a0ab632",
      "5a513dc0c6a042e8b85b9dc22c529b8f",
      "db357699e41b40b29aee367965a6e00d",
      "2059b6430ae24a979433c817a400be94",
      "5f025b5eca974889a844e039869fbc71",
      "8412f53955f84016a39864a0ab9ec849",
      "ed840ec3453a4177993169f74b15d46f",
      "df8c0392f2cc434e994608989cd0c813",
      "137ad855ae0042688a30e2aacc5c2a0e",
      "cfb55f7e00b14028a82da1480b17cd4a",
      "5505e2fb89fd48e4b29fb6326d98434c",
      "11f2841130f243dd90e82000bf28260f",
      "a16e8d5edc0c4a5bb9c0f8f2cd8d8451",
      "d109efa229b749e58032240693bc22ca",
      "86fa1f9a8fda491db82600464f7f3bb4",
      "603fcf2ea7754542a928e86c4a4b4f06",
      "1797f54d91ee470497506de3578e9ca9",
      "cbc3a3ce68c246ad8440b98a9515460a",
      "8901f79918ba4baea5a495fb38b8c7d4",
      "269549f64da144d6b8175371eb3e6835",
      "60558819a8d54550a01013eccefe04fb",
      "b8abfb8e66a14b6988db332ad0225fce",
      "55c0330a8eeb45bca031e57dee699db9",
      "1e3e92709e424b1582b6ced54878baca",
      "b9dad7842f5f4e9d9789113710345b51",
      "d558503764e842beb56109a7fd26af17",
      "e4dbc2470c2849a28cf049a1e2c6be55",
      "57d43264d22e4b18b0c17143838e0ed9",
      "9379d87c274643b5b4f35e2969b59292",
      "6d8d5af61ef045b0bf2003303e362cf8",
      "2e12efae90f4433ca0d2d3c508086e76",
      "1609bc629cc9498b80833e5ea3459bc3",
      "071e2820554546d0a9e744aaf1063aa7",
      "19168f62ab184ae98cff6b9d720a8fa9",
      "50a79e691caf4d5f9e400b376f2b7ee5",
      "07935f3200644a81854789de819ed185",
      "9a86e7f3734f4900a7bfffe014d3436e",
      "255939740f6749f4bfe0977f31e86e94",
      "f0559b799531438eb885cd5ca2d99b08",
      "613e5dae43aa47749df476ca3bb8c01f",
      "f408ebf06c43457a9f0025142d1011c8",
      "c8ce68a23ea643a99f0ae4b0d57405f3",
      "722c8c6c24704415aea007e3c57c835a",
      "40133cac1ae94b33b03027024744fd1d",
      "9bc684f31b884358b7f4b9bd6a1230b3",
      "ac5b5d546c73486397262ac34eaed777",
      "8d8205a6dd13437781eaef29f7ed9309",
      "7920397d77784d59beaacf484d3063c6",
      "c999521c1b8f4f18bd6c40338c4b01df",
      "fd7837954f904b2b9d766bf417407992",
      "8513a975b2234e7290fcd7e036afb49f",
      "13483b63638848f48c3e9f513405be37"
     ]
    },
    "id": "N95keytawWSd",
    "outputId": "f70e3521-1c4b-4583-e1ff-ee43815a41dd"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Load training and testing datasets\n",
    "df = pd.read_csv(\"/content/symptom_train.csv\")\n",
    "df_test = pd.read_csv(\"/content/symptom_test.csv\")\n",
    "\n",
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Data Preprocessing: prepare Huggingface Dataset objects\n",
    "# Rename columns to 'text' and 'label' for Huggingface compatibility\n",
    "train_dataset = Dataset.from_pandas(df[[\"Abstract\", \"MentionsSymptom\"]].rename(columns={\"Abstract\": \"text\", \"MentionsSymptom\": \"label\"}))\n",
    "test_dataset = Dataset.from_pandas(df_test[[\"Abstract\", \"MentionsSymptom\"]].rename(columns={\"Abstract\": \"text\", \"MentionsSymptom\": \"label\"}))\n",
    "\n",
    "# Tokenize the datasets\n",
    "train_dataset = train_dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\"), batched=True)\n",
    "test_dataset = test_dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\"), batched=True)\n",
    "\n",
    "# Define label map and load model\n",
    "id2label = {0: \"No Symptom\", 1: \"Mentions Symptom\"}\n",
    "label2id = {\"No Symptom\": 0, \"Mentions Symptom\": 1}\n",
    "\n",
    "# Load DistilBERT model for sequence classification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2, # Binary classification (0 or 1)\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "\n",
    "# Set training arguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "from transformers import (AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"text_classification_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",                      # run eval at the end of each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True  # # Use FP16 (faster on GPUs) with Colab\n",
    ")\n",
    "\n",
    "\n",
    "# Define custom evaluation metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    auc = roc_auc_score(labels, pred.predictions[:, 1])\n",
    "    report = classification_report(labels, preds, output_dict=True)\n",
    "    return {\n",
    "        \"accuracy\": report[\"accuracy\"],        # Overall accuracy\n",
    "        \"precision\": report[\"1\"][\"precision\"], # Precision for class '1' (Mentions Symptom)\n",
    "        \"recall\": report[\"1\"][\"recall\"],       # Recall for class '1'\n",
    "        \"f1\": report[\"1\"][\"f1-score\"],         # F1-score for class '1'\n",
    "        \"roc_auc\": auc                         # ROC-AUC score\n",
    "    }\n",
    "\n",
    "\n",
    "# Initialize Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train() # Start training\n",
    "trainer.evaluate() # Final evaluation on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twEi7-NCwWSe",
    "outputId": "3e8ba325-fc2c-4ff3-c959-47cb8a6a6d62"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYndRGsR6HGj",
    "outputId": "dcea5fc7-0b42-457f-8360-261955f08eba"
   },
   "outputs": [],
   "source": [
    "! pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "76ef3f2329564865b8e811bbb9f14a24",
      "9b599f760fca4d1eb51a1c2ef91c67fe",
      "16ec9834c18340919f787ee89954fde7",
      "29f3cd980a22495e847e366981be0a9d",
      "f3a1252c61124d96b50dae6a2f53e124",
      "a44871785a6b48d3a0fa0f8c4949ef3d",
      "c9682c5b386048a48d0491a8c6507e74",
      "f2290dea7dff4516a413f50be27d23e7",
      "0f68ff43396249c1bacfff1162e9efdf",
      "a3f6de610788417c9e7d20fa13765cd9",
      "b3d9e2e1c49c465ba92dbfae97aa8472"
     ]
    },
    "id": "32M7IhOfwWSe",
    "outputId": "de8b4d63-c3bc-4dd9-de88-6b5ccbf994f6"
   },
   "outputs": [],
   "source": [
    "# Define evaluation metric\n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yFmTO12wWSe"
   },
   "outputs": [],
   "source": [
    "# Custom function to compute metrics during evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred # Unpack predictions and true labels\n",
    "    preds = np.argmax(predictions, axis=1) # Take the class with the highest probability\n",
    "    return accuracy.compute(predictions=preds, references=labels) # Return computed accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ts1IzBVcwWSe",
    "outputId": "0c155712-50cc-425c-94bd-99c6981c4f7a"
   },
   "outputs": [],
   "source": [
    "# Use Trainer to make final predictions on the test dataset\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGjncFH9wWSe",
    "outputId": "fac688e5-1738-463b-e50b-229cb7fc1623"
   },
   "outputs": [],
   "source": [
    "print(predictions.predictions)  # Model's predicted logits (2D array: samples x 2 classes)\n",
    "print(predictions.label_ids)    # True labels (1D array)\n",
    "print(predictions.metrics)      # Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5pvGjCRwWSe"
   },
   "outputs": [],
   "source": [
    "# Convert logits to final class predictions\n",
    "y_pred_accuracy = np.argmax(predictions.predictions, axis=1) # Take the index of the highest logit (class 0 or 1)\n",
    "y_true_accuracy = predictions.label_ids # True labels extracted from predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epcwzKEewWSe",
    "outputId": "3a1a0f2a-cdb9-4fea-e90c-fbea38355104"
   },
   "outputs": [],
   "source": [
    "# Print a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(\n",
    "    y_true_accuracy, y_pred_accuracy,\n",
    "    labels=[0, 1], # Define the label order\n",
    "    target_names=[\"No Symptom\", \"Mentions Symptom\"], # Label names for readability\n",
    "    digits=4 # Display results with 4 decimal places\n",
    ")\n",
    "print(report)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# Print confusion matrix and overall accuracy\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true_accuracy, y_pred_accuracy, labels=[0, 1]))\n",
    "\n",
    "print(\"\\nOverall Accuracy:\", accuracy_score(y_true_accuracy, y_pred_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
